import os
import sys
import pickle
import pandas as pd
import numpy as np
from datetime import datetime
import psycopg2
from psycopg2 import Error, pool
from psycopg2.extras import RealDictCursor

# Import scikit-learn models ƒë·ªÉ pickle c√≥ th·ªÉ load
from sklearn.linear_model import LogisticRegression
from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier

# Th√™m th∆∞ m·ª•c g·ªëc v√†o sys.path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# Import database utilities n·∫øu c√≥
try:
    from config.database import init_connection_pool, get_connection
    USE_DB_UTILS = True
except:
    USE_DB_UTILS = False

class SentimentAnalyzer:
    def __init__(self):
        """Kh·ªüi t·∫°o Sentiment Analyzer"""
        self.model = None
        self.vectorizer = None
        self.db_connection = None
        
    def load_model(self, model_path='models/sentiment_model_bilingual.pkl'):
        """Load model ƒë√£ train (pickle file)"""
        try:
            print(f"üì¶ ƒêang load model t·ª´ {model_path}...")
            
            if not os.path.exists(model_path):
                print(f"‚úó Kh√¥ng t√¨m th·∫•y file: {model_path}")
                return False
            
            with open(model_path, 'rb') as f:
                model_data = pickle.load(f)
            
            # Ki·ªÉm tra xem model_data c√≥ ch·ª©a g√¨
            if isinstance(model_data, dict):
                # N·∫øu l√† dict, c√≥ th·ªÉ ch·ª©a c·∫£ model v√† vectorizer
                self.model = model_data.get('model')
                self.vectorizer = model_data.get('vectorizer') or model_data.get('tfidf')
                print("‚úì Load model v√† vectorizer t·ª´ dict th√†nh c√¥ng!")
            else:
                # N·∫øu ch·ªâ l√† model
                self.model = model_data
                print("‚úì Load model th√†nh c√¥ng!")
                print("‚ö† C·∫ßn load vectorizer ri√™ng...")
            
            return True
        except Exception as e:
            print(f"‚úó L·ªói khi load model: {str(e)}")
            import traceback
            traceback.print_exc()
            return False
    
    def load_vectorizer(self, vectorizer_path='models/tfidf_vectorizer.pkl'):
        """Load vectorizer/tokenizer ri√™ng n·∫øu c·∫ßn"""
        try:
            if self.vectorizer is not None:
                print("‚úì Vectorizer ƒë√£ ƒë∆∞·ª£c load c√πng model")
                return True
                
            print(f"üì¶ ƒêang load vectorizer t·ª´ {vectorizer_path}...")
            
            if not os.path.exists(vectorizer_path):
                print(f"‚ö† Kh√¥ng t√¨m th·∫•y file: {vectorizer_path}")
                # Th·ª≠ t√¨m file vectorizer kh√°c
                alt_paths = [
                    'models/vectorizer.pkl',
                    'models/tokenizer.pkl',
                    'tfidf_vectorizer.pkl',
                    'vectorizer.pkl'
                ]
                for alt_path in alt_paths:
                    if os.path.exists(alt_path):
                        vectorizer_path = alt_path
                        print(f"  ‚úì T√¨m th·∫•y: {alt_path}")
                        break
                else:
                    print("‚ö† Kh√¥ng t√¨m th·∫•y vectorizer ri√™ng!")
                    print("üí° Model c√≥ th·ªÉ kh√¥ng c·∫ßn vectorizer ho·∫∑c ƒë√£ t√≠ch h·ª£p s·∫µn")
                    print("   S·∫Ω th·ª≠ ch·∫°y tr·ª±c ti·∫øp v·ªõi model...")
                    return True  # Cho ph√©p ti·∫øp t·ª•c
            else:
                with open(vectorizer_path, 'rb') as f:
                    self.vectorizer = pickle.load(f)
                print("‚úì Load vectorizer th√†nh c√¥ng!")
            
            return True
        except Exception as e:
            print(f"‚ö† L·ªói khi load vectorizer: {str(e)}")
            print("   S·∫Ω th·ª≠ ch·∫°y tr·ª±c ti·∫øp v·ªõi model...")
            return True  # Cho ph√©p ti·∫øp t·ª•c
    
    def connect_database(self, host='localhost', database='LibManage', 
                        user='postgres', password='', port=5432):
        """K·∫øt n·ªëi ƒë·∫øn PostgreSQL database"""
        try:
            print(f"üîå ƒêang k·∫øt n·ªëi ƒë·∫øn PostgreSQL database {database}...")
            
            if USE_DB_UTILS:
                # S·ª≠ d·ª•ng utility c√≥ s·∫µn
                self.db_connection = get_connection()
                print("‚úì S·ª≠ d·ª•ng connection pool t·ª´ config")
            else:
                # K·∫øt n·ªëi tr·ª±c ti·∫øp
                self.db_connection = psycopg2.connect(
                    host=host,
                    database=database,
                    user=user,
                    password=password,
                    port=port
                )
            
            if self.db_connection:
                # Test connection
                cursor = self.db_connection.cursor()
                cursor.execute('SELECT version();')
                db_version = cursor.fetchone()
                cursor.close()
                print(f"‚úì K·∫øt n·ªëi PostgreSQL th√†nh c√¥ng!")
                print(f"  Database version: {db_version[0][:50]}...")
                return True
                
        except Error as e:
            print(f"‚úó L·ªói k·∫øt n·ªëi PostgreSQL: {str(e)}")
            print(f"\nüí° H∆∞·ªõng d·∫´n kh·∫Øc ph·ª•c:")
            print(f"   1. Ki·ªÉm tra PostgreSQL ƒë√£ ch·∫°y ch∆∞a")
            print(f"   2. Ki·ªÉm tra username/password")
            print(f"   3. Ki·ªÉm tra t√™n database: {database}")
            print(f"   4. Ki·ªÉm tra port: {port} (m·∫∑c ƒë·ªãnh l√† 5432)")
            return False
    
    def preprocess_text(self, text):
        """Ti·ªÅn x·ª≠ l√Ω text tr∆∞·ªõc khi ph√¢n t√≠ch"""
        if not text or text.strip() == '':
            return ''
        
        # Chuy·ªÉn v·ªÅ lowercase
        text = text.lower().strip()
        return text
    
    def predict_sentiment(self, text):
        """D·ª± ƒëo√°n sentiment cho m·ªôt ƒëo·∫°n text"""
        try:
            # Ti·ªÅn x·ª≠ l√Ω
            processed_text = self.preprocess_text(text)
            
            if not processed_text:
                return None
            
            # Vector h√≥a text
            if self.vectorizer:
                text_vector = self.vectorizer.transform([processed_text])
            else:
                # N·∫øu kh√¥ng c√≥ vectorizer, d√πng tr·ª±c ti·∫øp text
                text_vector = [processed_text]
            
            # D·ª± ƒëo√°n
            prediction = self.model.predict(text_vector)[0]
            
            # L·∫•y probability n·∫øu c√≥
            try:
                proba = self.model.predict_proba(text_vector)[0]
                confidence = float(max(proba))
                
                # N·∫øu l√† binary classification
                if len(proba) == 2:
                    sentiment_score = float(proba[1])  # Probability c·ªßa class positive
                else:
                    sentiment_score = confidence
            except:
                confidence = 0.5
                sentiment_score = 0.5 if prediction == 1 else 0.5
            
            # Map prediction sang label
            # Gi·∫£ s·ª≠: 0 = Negative, 1 = Positive, 2 = Neutral (n·∫øu c√≥)
            label_map = {
                0: 'Negative',
                1: 'Positive',
                2: 'Neutral'
            }
            sentiment_label = label_map.get(prediction, 'Unknown')
            
            return {
                'text': text,
                'sentiment': sentiment_label,
                'score': sentiment_score,
                'confidence': confidence
            }
            
        except Exception as e:
            print(f"‚úó L·ªói khi d·ª± ƒëo√°n: {str(e)}")
            import traceback
            traceback.print_exc()
            return None
    
    def get_reviews_from_db(self, table_name='reviews', limit=None):
        """L·∫•y c√°c review ch∆∞a ph√¢n t√≠ch t·ª´ PostgreSQL database"""
        try:
            cursor = self.db_connection.cursor(cursor_factory=RealDictCursor)
            
            # Query l·∫•y reviews ch∆∞a ƒë∆∞·ª£c ph√¢n t√≠ch
            # PostgreSQL s·ª≠ d·ª•ng %s thay v√¨ ? cho placeholders
            query = f"""
                SELECT id, review_text, user_id, book_id, created_at 
                FROM {table_name} 
                WHERE sentiment IS NULL OR sentiment = ''
            """
            
            if limit:
                query += f" LIMIT {limit}"
            
            cursor.execute(query)
            reviews = cursor.fetchall()
            cursor.close()
            
            print(f"‚úì ƒê√£ l·∫•y {len(reviews)} reviews c·∫ßn ph√¢n t√≠ch")
            return reviews
            
        except Error as e:
            print(f"‚úó L·ªói khi l·∫•y reviews: {str(e)}")
            return []
    
    def save_sentiment_to_db(self, review_id, sentiment_result, table_name='reviews'):
        """L∆∞u k·∫øt qu·∫£ ph√¢n t√≠ch sentiment v√†o PostgreSQL database"""
        try:
            cursor = self.db_connection.cursor()
            
            # PostgreSQL s·ª≠ d·ª•ng %s cho t·∫•t c·∫£ placeholders
            update_query = f"""
                UPDATE {table_name} 
                SET sentiment = %s, 
                    sentiment_score = %s, 
                    sentiment_confidence = %s,
                    analyzed_at = %s
                WHERE id = %s
            """
            
            values = (
                sentiment_result['sentiment'],
                sentiment_result['score'],
                sentiment_result['confidence'],
                datetime.now(),
                review_id
            )
            
            cursor.execute(update_query, values)
            self.db_connection.commit()
            cursor.close()
            
            return True
            
        except Error as e:
            print(f"‚úó L·ªói khi l∆∞u sentiment (review_id={review_id}): {str(e)}")
            # Rollback n·∫øu c√≥ l·ªói
            self.db_connection.rollback()
            import traceback
            traceback.print_exc()
            return False
    
    def analyze_and_save_batch(self, reviews, table_name='reviews'):
        """Ph√¢n t√≠ch v√† l∆∞u m·ªôt batch reviews"""
        success_count = 0
        fail_count = 0
        
        print(f"\nüîÑ B·∫Øt ƒë·∫ßu ph√¢n t√≠ch {len(reviews)} reviews...")
        print("-" * 80)
        
        for i, review in enumerate(reviews, 1):
            try:
                review_text = review.get('review_text', '') or review.get('content', '')
                
                if not review_text or review_text.strip() == '':
                    print(f"  [{i}/{len(reviews)}] ‚ö† Review ID {review['id']}: N·ªôi dung tr·ªëng")
                    fail_count += 1
                    continue
                
                # D·ª± ƒëo√°n sentiment
                sentiment_result = self.predict_sentiment(review_text)
                
                if sentiment_result:
                    # L∆∞u v√†o database
                    if self.save_sentiment_to_db(review['id'], sentiment_result, table_name):
                        success_count += 1
                        # Hi·ªÉn th·ªã preview text
                        preview = review_text[:50] + "..." if len(review_text) > 50 else review_text
                        print(f"  [{i}/{len(reviews)}] ‚úì ID {review['id']}: {sentiment_result['sentiment']} "
                              f"(score: {sentiment_result['score']:.3f}, conf: {sentiment_result['confidence']:.3f})")
                        print(f"      Text: {preview}")
                    else:
                        fail_count += 1
                else:
                    fail_count += 1
                    print(f"  [{i}/{len(reviews)}] ‚úó Review ID {review['id']}: L·ªói d·ª± ƒëo√°n")
                    
            except Exception as e:
                fail_count += 1
                print(f"  [{i}/{len(reviews)}] ‚úó Review ID {review['id']}: {str(e)}")
        
        print("-" * 80)
        print(f"\nüìä K·∫øt qu·∫£:")
        print(f"  ‚úì Th√†nh c√¥ng: {success_count}/{len(reviews)}")
        print(f"  ‚úó Th·∫•t b·∫°i: {fail_count}/{len(reviews)}")
        if len(reviews) > 0:
            print(f"  üìà T·ª∑ l·ªá th√†nh c√¥ng: {success_count/len(reviews)*100:.1f}%")
        
        return success_count, fail_count
    
    def run_analysis(self, batch_size=100, table_name='reviews'):
        """Ch·∫°y to√†n b·ªô quy tr√¨nh ph√¢n t√≠ch sentiment"""
        print("=" * 80)
        print("  SENTIMENT ANALYSIS - LibManage System (PostgreSQL)")
        print("=" * 80)
        
        # Load model
        if not self.load_model():
            return False
        
        # Load vectorizer n·∫øu c·∫ßn
        if not self.vectorizer:
            self.load_vectorizer()
        
        # K·∫øt n·ªëi database
        if not self.connect_database():
            return False
        
        # L·∫•y reviews c·∫ßn ph√¢n t√≠ch
        reviews = self.get_reviews_from_db(table_name, limit=batch_size)
        
        if not reviews:
            print("\n‚ö† Kh√¥ng c√≥ review n√†o c·∫ßn ph√¢n t√≠ch!")
            print("üí° H√£y ki·ªÉm tra:")
            print("   - B·∫£ng 'reviews' c√≥ t·ªìn t·∫°i kh√¥ng?")
            print("   - C√≥ reviews n√†o v·ªõi sentiment = NULL kh√¥ng?")
            return True
        
        # Ph√¢n t√≠ch v√† l∆∞u
        success, fail = self.analyze_and_save_batch(reviews, table_name)
        
        # ƒê√≥ng k·∫øt n·ªëi
        if self.db_connection:
            self.db_connection.close()
            print("\n‚úì ƒê√£ ƒë√≥ng k·∫øt n·ªëi database")
        
        print("\n" + "=" * 80)
        print("  HO√ÄN TH√ÄNH!")
        print("=" * 80)
        
        return True
    
    def close(self):
        """ƒê√≥ng t·∫•t c·∫£ k·∫øt n·ªëi"""
        if self.db_connection:
            self.db_connection.close()


def main():
    """Main function"""
    print("\nüöÄ Kh·ªüi ƒë·ªông Sentiment Analysis System (PostgreSQL)...\n")
    
    # C·∫•u h√¨nh PostgreSQL - ƒêI·ªÄU CH·ªàNH THEO H·ªÜ TH·ªêNG C·ª¶A B·∫†N
    CONFIG = {
        'model_path': 'models/sentiment_model_bilingual.pkl',
        'vectorizer_path': 'models/tfidf_vectorizer.pkl',
        'db_host': 'localhost',
        'db_name': 'LibManage',  # T√™n database PostgreSQL
        'db_user': 'postgres',   # User PostgreSQL (m·∫∑c ƒë·ªãnh l√† postgres)
        'db_password': '',       # ‚ö†Ô∏è TH√äM PASSWORD POSTGRESQL C·ª¶A B·∫†N
        'db_port': 5432,         # Port PostgreSQL (m·∫∑c ƒë·ªãnh l√† 5432)
        'table_name': 'reviews', # B·∫£ng ch·ª©a reviews
        'batch_size': 100        # S·ªë l∆∞·ª£ng reviews ph√¢n t√≠ch m·ªói l·∫ßn
    }
    
    print("‚öôÔ∏è  C·∫•u h√¨nh hi·ªán t·∫°i:")
    print(f"   üêò Database: PostgreSQL - {CONFIG['db_name']}")
    print(f"   üîå Host: {CONFIG['db_host']}:{CONFIG['db_port']}")
    print(f"   üë§ User: {CONFIG['db_user']}")
    print(f"   üìã Table: {CONFIG['table_name']}")
    print(f"   üì¶ Model: {CONFIG['model_path']}")
    print(f"   üî¢ Batch size: {CONFIG['batch_size']}")
    print()
    
    # Kh·ªüi t·∫°o analyzer
    analyzer = SentimentAnalyzer()
    
    # Ch·∫°y ph√¢n t√≠ch
    try:
        success = analyzer.run_analysis(
            batch_size=CONFIG['batch_size'],
            table_name=CONFIG['table_name']
        )
        
        if success:
            print("\n‚úÖ Ch∆∞∆°ng tr√¨nh ch·∫°y th√†nh c√¥ng!")
        else:
            print("\n‚ùå C√≥ l·ªói x·∫£y ra trong qu√° tr√¨nh ch·∫°y!")
            print("\nüí° H√£y ki·ªÉm tra:")
            print("   1. PostgreSQL ƒë√£ ch·∫°y ch∆∞a?")
            print("   2. Database 'LibManage' c√≥ t·ªìn t·∫°i kh√¥ng?")
            print("   3. B·∫£ng 'reviews' c√≥ t·ªìn t·∫°i kh√¥ng?")
            print("   4. User c√≥ quy·ªÅn truy c·∫≠p kh√¥ng?")
            print("   5. Password c√≥ ƒë√∫ng kh√¥ng?")
            
    except KeyboardInterrupt:
        print("\n\n‚ö† Ng∆∞·ªùi d√πng d·ª´ng ch∆∞∆°ng tr√¨nh!")
    except Exception as e:
        print(f"\n‚ùå L·ªói kh√¥ng mong mu·ªën: {str(e)}")
        import traceback
        traceback.print_exc()
    finally:
        analyzer.close()


if __name__ == "__main__":
    main()
